# 项目：buggy-paper-translator

###  项目背景：

在科研过程中，我们需要快速浏览海量的英文文献。为了加快扫描文献的速度，我们通常会使用一些大模型来帮我们把扫下来的文献翻译成中文。要在没有本地 GPU 显存的情况下实现这一目标，我们需要利用云端的大模型推理服务。该项目通过脚本调用Hugging Face的Inference API来使用一些免费的大模型来翻译论文。

###  环境配置：

在将该项目代码下载到本地之后，需要先安装对应的包，具体列举在requirements_fixed.txt 文件中。然后完成注册一个Hugging Face平台账号，并申请一个Access Token，并将该token的值配置在电脑的环境变量中使得脚本能成功读取，变量名设置为HF_TOKEN,值设置为你的token值。

### 如何运行：

在以上环境都配置完毕之后，需要保证你的网络能访问Hugging Face，这个网站的服务器在国外，可能会出现远程主机关闭现有连接这个错误，使得程序无法成功运行。在确保这个之后，需要翻译的写在iccv2025.csv这个文件里面，然后在直接运行程序即可。

